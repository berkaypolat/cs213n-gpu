{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "import torch.nn.functional as func\n",
    "from util_datasets import GaussianNoise, UniformNoise\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "class_names = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', \n",
    "               'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "               'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']\n",
    "\n",
    "imgtransResize = (320, 320)\n",
    "imgtransCrop = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import CheXpertTrainer \n",
    "from chexpertClass import CheXpertData\n",
    "from denseNet121 import DenseNet121\n",
    "from utils import *\n",
    "from ood_evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORM DATA SEQUENCE\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "transformList = []\n",
    "#transformList.append(transforms.Resize(imgtransCrop))\n",
    "transformList.append(transforms.RandomResizedCrop(imgtransCrop))\n",
    "transformList.append(transforms.RandomHorizontalFlip())\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)      \n",
    "transformSequence=transforms.Compose(transformList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  223414\n",
      "Valid set:  234\n",
      "New train set:  221648\n",
      "New valid set:  1000\n",
      "New test set:  1000\n"
     ]
    }
   ],
   "source": [
    "#CheXpert dataset loading\n",
    "chex_datasetValid = CheXpertData('datasets/chexpert-small/CheXpert-v1.0-small/valid.csv',transformSequence, preload = True, policy=\"ones\")\n",
    "chex_datasetTrain = CheXpertData('datasets/chexpert-small/CheXpert-v1.0-small/train.csv',transformSequence, policy=\"ones\")\n",
    "print(\"Train set: \", len(chex_datasetTrain))\n",
    "print(\"Valid set: \", len(chex_datasetValid))\n",
    "datasetValid, datasetTrain = random_split(chex_datasetTrain, [766, len(chex_datasetTrain) - 766])\n",
    "chex_test, chex_train = random_split(datasetTrain, [1000, len(datasetTrain) - 1000])\n",
    "\n",
    "#split datasets into train,valid,test\n",
    "chex_valid = torch.utils.data.ConcatDataset([chex_datasetValid, datasetValid])\n",
    "print(\"New train set: \", len(chex_train))\n",
    "print(\"New valid set: \", len(chex_valid))\n",
    "print(\"New test set: \", len(chex_test))\n",
    "dataLoaderTrain = DataLoader(dataset=chex_train, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "dataLoaderValid = DataLoader(dataset=chex_valid, batch_size=32, shuffle=False,  num_workers=1, pin_memory=True)\n",
    "dataLoaderTest = DataLoader(dataset=chex_test, batch_size=32, shuffle=False,  num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIH train set:  4606\n",
      "NIH valid set:  1000\n"
     ]
    }
   ],
   "source": [
    "#NIH dataset loading\n",
    "nih_dataset = datasets.ImageFolder(root='datasets/nih-small/small', transform = transformSequence)\n",
    "nih_test, nih_train = random_split(nih_dataset, [1000, len(nih_dataset) - 1000])\n",
    "print(\"NIH train set: \", len(nih_train))\n",
    "print(\"NIH valid set: \", len(nih_test))\n",
    "dataLoaderNIH = DataLoader(dataset=nih_test, batch_size=32, shuffle=False,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'cheXpert_github/model_ones_3epoch_densenet.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CheXpertTrainer(model, class_names, checkpoint_path, use_cuda, device, epoch = 3)\n",
    "dataLoaders = [dataLoaderTrain, dataLoaderValid]\n",
    "lost_train, loss_eval = trainer.train(dataLoaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ind_scores, ind_gt, ind_conf = evaluate_ood(dataLoaderTest, 'confidence', model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment without the pretrained weights\n",
    "trainer = CheXpertTrainer(model = model, class_names = class_names, use_cuda = use_cuda, device = device, epoch = 3)\n",
    "dataLoaders = [dataLoaderTrain, dataLoaderValid]\n",
    "new_lost_train, new_loss_eval = trainer.train(dataLoaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Traininig for Model with adjusted DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch #1: 100%|██████████| 6927/6927 [2:48:05<00:00,  1.28s/it]  \n",
      "Eval Epoch #1: 100%|██████████| 32/32 [00:40<00:00,  1.15s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss after epoch  1 :  0.28676509857177734\n",
      "Eval Loss after epoch  1 :  0.317018061876297\n",
      "AUROC scores after epoch  1 :\n",
      "Validation set: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Progress..: 100%|██████████| 32/32 [00:14<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC mean  0.7453734910648304\n",
      "No Finding   0.8589944134078213\n",
      "Enlarged Cardiomediastinum   0.5861370378409666\n",
      "Cardiomegaly   0.7988642976102094\n",
      "Lung Opacity   0.7290660225442835\n",
      "Lung Lesion   0.7250520833333333\n",
      "Edema   0.8441668155113903\n",
      "Consolidation   0.668569816491577\n",
      "Pneumonia   0.6851068853021979\n",
      "Atelectasis   0.6696706552706552\n",
      "Pneumothorax   0.7602727305697602\n",
      "Pleural Effusion   0.8477728344879151\n",
      "Pleural Other   0.777326565143824\n",
      "Fracture   0.6412435233160622\n",
      "Support Devices   0.8429851940776311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch #2: 100%|██████████| 6927/6927 [2:47:50<00:00,  1.27s/it]  \n",
      "Eval Epoch #2: 100%|██████████| 32/32 [00:39<00:00,  1.11s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss after epoch  2 :  0.40993526577949524\n",
      "Eval Loss after epoch  2 :  0.3154594600200653\n",
      "AUROC scores after epoch  2 :\n",
      "Validation set: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Progress..: 100%|██████████| 32/32 [00:14<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC mean  0.7507619531747965\n",
      "No Finding   0.8437882415536047\n",
      "Enlarged Cardiomediastinum   0.5566825186968447\n",
      "Cardiomegaly   0.7552287122686625\n",
      "Lung Opacity   0.7084983896940418\n",
      "Lung Lesion   0.7038802083333333\n",
      "Edema   0.8468798123108263\n",
      "Consolidation   0.6640761439049947\n",
      "Pneumonia   0.7181490384615383\n",
      "Atelectasis   0.688888888888889\n",
      "Pneumothorax   0.7920671187997921\n",
      "Pleural Effusion   0.8433610515575494\n",
      "Pleural Other   0.7910659898477157\n",
      "Fracture   0.7286454478164324\n",
      "Support Devices   0.8694557823129251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch #3: 100%|██████████| 6927/6927 [2:47:52<00:00,  1.27s/it]  \n",
      "Eval Epoch #3: 100%|██████████| 32/32 [00:31<00:00,  1.11it/s]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss after epoch  3 :  0.35181933641433716\n",
      "Eval Loss after epoch  3 :  0.3312612473964691\n",
      "AUROC scores after epoch  3 :\n",
      "Validation set: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Progress..: 100%|██████████| 32/32 [00:14<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC mean  0.7519502087208524\n",
      "No Finding   0.8517052407555199\n",
      "Enlarged Cardiomediastinum   0.6100137471962955\n",
      "Cardiomegaly   0.7978008307081085\n",
      "Lung Opacity   0.7236151368760064\n",
      "Lung Lesion   0.7275260416666667\n",
      "Edema   0.8419510405453027\n",
      "Consolidation   0.6608788521991457\n",
      "Pneumonia   0.7046381353021979\n",
      "Atelectasis   0.7042279202279202\n",
      "Pneumothorax   0.7843300813597844\n",
      "Pleural Effusion   0.8519615497420263\n",
      "Pleural Other   0.6941455160744501\n",
      "Fracture   0.6983863804589194\n",
      "Support Devices   0.8761224489795918\n"
     ]
    }
   ],
   "source": [
    "from denseNet121_v2 import *\n",
    "from trainer_v2 import *\n",
    "\n",
    "model = DenseNet121v2(len(class_names)).to(device)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "trainer = CheXpertTrainerv2(model = model, class_names = class_names, use_cuda = use_cuda, device = device, epoch = 3)\n",
    "dataLoaders = [dataLoaderTrain, dataLoaderValid]\n",
    "new_lost_train, new_loss_eval = trainer.train(dataLoaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
